{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SI 330: Homework 8: Databases & SQL\n",
    "\n",
    "\n",
    "## Due: Friday, March 23, 2018,  11:59:00pm\n",
    "\n",
    "### Submission instructions</font>\n",
    "After completing this homework, you should turn in two files via Canvas ->  Assignments -> HW 7:\n",
    "Your Notebook, named si330-hw7-YOUR_UNIQUE_NAME.ipynb and\n",
    "the HTML file, named si330-hw7-YOUR_UNIQUE_NAME.html.\n",
    "\n",
    "### Name:  Dingan Chen\n",
    "### Uniqname: Dinganc\n",
    "### People you worked with: I worked by myself\n",
    "\n",
    "\n",
    "## Learning Objectives\n",
    "After completing this Homework, you should know how to:\n",
    "* create a postgreSQL database on AWS Relational Database Service (RDS)\n",
    "* load the contents of a CSV file into a pandas DataFrame\n",
    "* manipulate a pandas DataFrame to extract information from a column\n",
    "* load the resulting dataframes into a postgreSQL database\n",
    "* issue SQL queries to answer real-world questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "We have generated a CSV file that consists of nearly 10,000 books from Goodreads.com.  \n",
    "The file is derived from a dataset called \"goodreads-10k\" (see http://fastml.com/goodbooks-10k-a-new-dataset-for-book-recommendations/ for more details; we are only using the books.csv file for this assignment).\n",
    "\n",
    "The purpose of this assignment is to take that CSV file, manipulate some of the data, and\n",
    "write the resulting dataset to a postgreSQL database. Whereas this may seem contrived,\n",
    "it models a real-world scenario in which the data would the be made available via\n",
    "an API (which may be a nice bonus assignment, don't you think?).\n",
    "\n",
    "We have identified six (6) steps beyond the initial setup to guide you through this \n",
    "assignment.  Each of the following steps is detailed below:\n",
    "* Step 0: Redefine a function to improve performance and load the required libraries\n",
    "* Step 1: Fill in the correct  parameters to create a new AWS RDS instance\n",
    "* Step 2. Read the CSV file\n",
    "* Step 3. Make a connection to your SQL Database\n",
    "* Step 4: Breaking out the \"authors\"\n",
    "* Step 5: Load your authors table into your postgreSQL database\n",
    "* Step 6. Query the database\n",
    "\n",
    "Places where you need to do something are indicated in <font color=\"magenta\">magenta</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Redefine a function to improve performance and load the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This must be run before import pandas\n",
    "# See pandas issue #8953 for an explanation\n",
    "from pandas.io.sql import SQLTable\n",
    "\n",
    "def _execute_insert(self, conn, keys, data_iter):\n",
    "    print(\"Using monkey-patched _execute_insert\")\n",
    "    data = [dict((k, v) for k, v in zip(keys, row)) for row in data_iter]\n",
    "    conn.execute(self.insert_statement().values(data))\n",
    "\n",
    "SQLTable._execute_insert = _execute_insert\n",
    "\n",
    "# Load required libraries\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Fill in the correct  parameters to create a new AWS RDS instance\n",
    "You should review Lab 8, log into your AWS Management Console, go to the RDS panel and \n",
    "create a new instance called si330wn2018-goodbooks-UNIQNAME (where UNIQNAME is replaced with your uniqname).\n",
    "\n",
    "Create a database called \"goodbooks\", with your choice of username and password.\n",
    "\n",
    "After your database is created, \n",
    "** <font color=\"magenta\">record the relevant parameters in the following code block: **\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endpoint = \"si330wn2018-goodbooks-dinganc.c2uyq5gyfjgu.us-east-1.rds.amazonaws.com\"\n",
    "username = \"dinganc\"\n",
    "password = \"glazeddonut\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DO NOT MODIFY THIS\n",
    "database = \"goodbooks\" # we asked you to use this name for the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Read the CSV file\n",
    "\n",
    "We have provided you the data as a csv file on a public S3 bucket as https://s3.amazonaws.com/si330w18-cteplovs/books.csv. \n",
    "The file has four columns, of which you'll only deal with `authors` and `book_id` for this assignment.\n",
    "You'll need to read the csv file (remember that you can pass a URL to ```pd.read_csv()```)and create a dataframe from it.\n",
    "<font color=\"magenta\">** Read the csv file and create the DataFrame. The datafile has 9980 rows in it; you should confirm that your dataframe has the correct number of rows. **</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9980\n"
     ]
    }
   ],
   "source": [
    "books = pd.read_csv('https://s3.amazonaws.com/si330w18-cteplovs/books.csv')\n",
    "print(len(books))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Make a connection to your SQL Database\n",
    "\n",
    "In this step we will be using the SQLAlchemy package to connect to and query the database.\n",
    "SQLAlchemy has many uses.  We're using it to allow us to use the pandas to_sql() function. \n",
    "We've provided the code to make the connection assuming that you have updated the variable in Step 1 above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This will establish a connection to your database, if you've set everything up properly\n",
    "engine = create_engine('postgresql://{0}:{1}@{2}:5432/{3}'.format(username,password,endpoint,database))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next code block, we are using the pandas method ```.to_sql()``` to write a table to the database. ```.to_sql()``` takes in 3 parameters: the table to be used, the SQLAlchemy connection to the database, and what to do if the table already exists."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using monkey-patched _execute_insert\n"
     ]
    }
   ],
   "source": [
    "books.to_sql('books',engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Breaking out the \"authors\"\n",
    "If you take a look at the books dataframe, you'll see the format of the authors field:\n",
    "```\n",
    "3160       James Patterson, Michael Ledwidge\n",
    "1278               Virgil, Robert Fitzgerald\n",
    "3106                       Patricia Cornwell\n",
    "4764                          Scott B. Smith\n",
    "1207                         Jennifer Probst\n",
    "9703                        Orson Scott Card\n",
    "7292                              R.L. Stine\n",
    "8612                             Bella Andre\n",
    "8718                             John Irving\n",
    "7167    Arnaldur Indriðason, Bernard Scudder\n",
    "```\n",
    "The author column contains all the authors of a book separated by commas.\n",
    "While this is useful to a human reader, it makes it very inefficient to \n",
    "search for a particular author, especially if the author you're looking\n",
    "for isn't the first author of the book.\n",
    "\n",
    "For that reason, we need to extract the author information and\n",
    "create a new DataFrame called authors.  The authors dataframe should consist of two columns: \"author\" and \"bookid\" (use lowercase for the column names -- just trust us on this one).  The dataframe should look like:\n",
    "```\n",
    "     author          bookid\n",
    "0\tSuzanne Collins 1\n",
    "1\tJ.K. Rowling    2\n",
    "2\tMary GrandPré   2\n",
    "3\tStephenie Meyer 3\n",
    "4\tHarper Lee      4\n",
    "```\n",
    "\n",
    "<font color=\"magenta\">** Create a pandas DataFrame called authors, based on the contents of the books table.**</font>\n",
    "Note that you will need to split the authors column on commas and strip whitespace from the resulting strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>bookid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Suzanne Collins</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>J.K. Rowling</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mary GrandPré</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stephenie Meyer</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Harper Lee</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            author  bookid\n",
       "0  Suzanne Collins       1\n",
       "1     J.K. Rowling       2\n",
       "2    Mary GrandPré       2\n",
       "3  Stephenie Meyer       3\n",
       "4       Harper Lee       4"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_list=[]\n",
    "for ix,value in books.iterrows():\n",
    "    for author in value['authors'].split(','):\n",
    "        author_list.append({'author':author.strip(),'bookid':value['id']})\n",
    "authors=pd.DataFrame.from_dict(author_list)\n",
    "authors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Load your authors table into your postgreSQL database\n",
    "Assuming you've created a pandas DataFrame called \"authors\", \n",
    "<font color=\"magenta\">** you should be able to \n",
    "just run the following code block:**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using monkey-patched _execute_insert\n"
     ]
    }
   ],
   "source": [
    "authors.to_sql('authors',engine,if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6. Query the database\n",
    "\n",
    "Now that you've set everything up, you should answer the following questions **USING SQL and based on the data provided**:\n",
    "\n",
    "Note: It might be better if you look at some reference on how to make SQL queries with SQLAlchemy. Conceptually and syntactically, it's similar to how you made queries with postgres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**1. Confirm that the number of unique (Hint: DISTINCT) authors is 5829.**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5829\n"
     ]
    }
   ],
   "source": [
    "print(len(engine.execute(\"SELECT DISTINCT author FROM authors\").fetchall()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**2.How many books has J.K. Rowling written?**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "print(len(engine.execute(\"SELECT author FROM authors WHERE author LIKE 'J.K. Rowling'\").fetchall()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**3. Who has co-authored books with J.K. Rowling?**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Albus Dumbledore', 'Robert Galbraith', 'Kennilworthy Whisp', 'Jack Thorne', 'Joel Holland', 'Rufus Beck', 'MinaLima', 'Newt Scamander', 'John Tiffany', 'Melissa Anelli', 'Mary GrandPré']\n"
     ]
    }
   ],
   "source": [
    "print([i[0] for i in engine.execute(\"SELECT DISTINCT author FROM authors WHERE bookid IN (SELECT bookid FROM authors WHERE author LIKE 'J.K. Rowling')\").fetchall() if  i[0]!= 'J.K. Rowling'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"magenta\">**4. Which book has the largest number of authors?  How many authors?  Who are they?**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "book 6202 has 47 authors\n",
      "which has authors Christopher Hitchens, Titus Lucretius Carus, Omar Khayyám, Thomas Hobbes, Baruch Spinoza, David Hume, James Boswell, Percy Bysshe Shelley, George Eliot, Charles Darwin, Leslie Stephen, Anatole France, Mark Twain, Joseph Conrad, Thomas Hardy, Emma Goldman, H.P. Lovecraft, Carl Van Doren, H.L. Mencken, Sigmund Freud, Albert Einstein, George Orwell, John Betjeman, Chapman Cohen, Bertrand Russell, Philip Larkin, Martin Gardner, Carl Sagan, John Updike, John Leslie Mackie, Michael Shermer, A.J. Ayer, Daniel C. Dennett, Charles Templeton, Richard Dawkins, Victor J. Stenger, Elizabeth S.  Anderson, Penn Jillette, Ian McEwan, Steven Weinberg, Salman Rushdie, Ibn Warraq, Sam Harris, A.C. Grayling, Ayaan Hirsi Ali, John Stuart Mill, Karl Marx\n"
     ]
    }
   ],
   "source": [
    "Q1=engine.execute(\"SELECT bookid, count(bookid) FROM authors GROUP by bookid ORDER BY count(bookid) DESC LIMIT 1\").fetchall()[0]\n",
    "Q2=[i[0] for i in engine.execute(\"SELECT author FROM authors WHERE bookid = '6202'\").fetchall()]\n",
    "print (\"book {} has {} authors\".format(Q1[0],Q1[1]))\n",
    "print (\"which has authors {}\".format(', '.join(Q2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Above and Beyond\n",
    "\n",
    "Besides the `books.csv` we have also provided two other csv files. You can use them to upload to create tables to your RDS and use it for this section. Make sure that you have used SQL in your above and beyond.\n",
    "\n",
    "Please also indicate in a separate markdown block why you think your work goes above and beyond."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n",
      "Using monkey-patched _execute_insert\n"
     ]
    }
   ],
   "source": [
    "to_read = pd.read_csv('to_read.csv')\n",
    "rating = pd.read_csv('ratings.csv')\n",
    "to_read.to_sql('to_read',engine,if_exists='replace',chunksize=150000)\n",
    "rating.to_sql('rating',engine,if_exists='replace',chunksize=150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top ten highest rated books\n",
      "\n",
      "ESV Study Bible |rating:  4.82\n",
      "The Days Are Just Packed: A Calvin and Hobbes Collection |rating:  4.78\n",
      "The Indispensable Calvin and Hobbes |rating:  4.78\n",
      "Attack of the Deranged Mutant Killer Monster Snow Goons |rating:  4.78\n",
      "The Divan |rating:  4.77\n",
      "There's Treasure Everywhere: A Calvin and Hobbes Collection |rating:  4.77\n",
      "Harry Potter Boxed Set, Books 1-5 (Harry Potter, #1-5) |rating:  4.77\n",
      "The Calvin and Hobbes Lazy Sunday Book |rating:  4.75\n",
      "It's a Magical World: A Calvin and Hobbes Collection |rating:  4.75\n",
      "The Authoritative Calvin and Hobbes: A Calvin and Hobbes Treasury |rating:  4.75\n"
     ]
    }
   ],
   "source": [
    "Q3=engine.execute(\"SELECT books.title,AVG(rating.rating) FROM rating LEFT JOIN books on rating.book_id=books.id GROUP by rating.book_id,books.title ORDER BY AVG(rating.rating) DESC LIMIT 10 \").fetchall()\n",
    "print(\"top ten highest rated books\\n\")\n",
    "for j in [(i[0],round(float(i[1]),2))for i in Q3]:\n",
    "    print(j[0],'|rating: ',j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top ten most rated books\n",
      "\n",
      "Harry Potter and the Sorcerer's Stone (Harry Potter, #1) |rating count:  100\n",
      "Twilight (Twilight, #1) |rating count:  100\n",
      "To Kill a Mockingbird |rating count:  100\n",
      "The Great Gatsby |rating count:  100\n",
      "The Fault in Our Stars |rating count:  100\n",
      "The Hobbit |rating count:  100\n",
      "The Catcher in the Rye |rating count:  100\n",
      "Angels & Demons  (Robert Langdon, #1) |rating count:  100\n",
      "Pride and Prejudice |rating count:  100\n",
      "The Hunger Games (The Hunger Games, #1) |rating count:  100\n"
     ]
    }
   ],
   "source": [
    "Q4=engine.execute(\"SELECT books.title,count(rating.rating) FROM rating LEFT JOIN books on rating.book_id=books.id GROUP by rating.book_id,books.title ORDER BY count(rating.rating) DESC LIMIT 10 \").fetchall()\n",
    "print(\"top ten most rated books\\n\")\n",
    "for j in [(i[0],int(i[1]))for i in Q4]:\n",
    "    print(j[0],'|rating count: ',j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top ten most wanted books in to read list\n",
      "\n",
      "The Book Thief |to read count:  2772\n",
      "All the Light We Cannot See |to read count:  1967\n",
      "Catch-22 |to read count:  1840\n",
      "1984 |to read count:  1812\n",
      "The Kite Runner |to read count:  1767\n",
      "Life of Pi |to read count:  1717\n",
      "Miss Peregrine’s Home for Peculiar Children (Miss Peregrine’s Peculiar Children, #1) |to read count:  1650\n",
      "A Game of Thrones (A Song of Ice and Fire, #1) |to read count:  1619\n",
      "Slaughterhouse-Five |to read count:  1608\n",
      "The Alchemist |to read count:  1576\n"
     ]
    }
   ],
   "source": [
    "Q5=engine.execute(\"SELECT books.title, count(to_read.book_id) FROM to_read LEFT JOIN books on to_read.book_id=books.id GROUP by to_read.book_id,books.title ORDER BY count(to_read.book_id) DESC LIMIT 10\").fetchall()\n",
    "print(\"top ten most wanted books in to read list\\n\")\n",
    "for j in [(i[0],int(i[1]))for i in Q5]:\n",
    "    print(j[0],'|to read count: ',j[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
